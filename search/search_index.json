{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SQLStream","text":"<p>A lightweight, pure-Python SQL query engine for CSV and Parquet files with lazy evaluation and intelligent optimizations.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># Query a CSV file\n$ sqlstream query \"SELECT * FROM 'data.csv' WHERE age &gt; 25\"\n\n# Join multiple files\n$ sqlstream query \"SELECT c.name, o.total FROM 'customers.csv' c JOIN 'orders.csv' o ON c.id = o.customer_id\"\n\n# Interactive mode for wide tables\n$ sqlstream query data.csv \"SELECT * FROM data\" --interactive\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p> Pure Python</p> <p>No database installation required. Works anywhere Python runs.</p> </li> <li> <p> Multiple Formats</p> <p>Support for CSV, Parquet files, and HTTP URLs.</p> </li> <li> <p> 10-100x Faster</p> <p>Optional pandas backend for massive performance boost.</p> </li> <li> <p> JOIN Support</p> <p>INNER, LEFT, RIGHT joins across multiple files.</p> </li> <li> <p> Aggregations</p> <p>GROUP BY with COUNT, SUM, AVG, MIN, MAX functions.</p> </li> <li> <p> Beautiful Output</p> <p>Rich tables, JSON, CSV with syntax highlighting.</p> </li> <li> <p> Interactive Mode</p> <p>Scrollable table viewer for wide data (Phase 7.5).</p> </li> <li> <p> Inline File Paths</p> <p>Specify files directly in SQL queries (Phase 7.6).</p> </li> <li> <p> Smart Optimizations</p> <p>Column pruning, predicate pushdown, lazy evaluation.</p> </li> </ul>"},{"location":"#installation","title":"Installation","text":"Basic (CSV only)With ParquetWith Pandas (10-100x faster)All Features <pre><code>pip install sqlstream\n</code></pre> <pre><code>pip install \"sqlstream[parquet]\"\n</code></pre> <pre><code>pip install \"sqlstream[pandas]\"\n</code></pre> <pre><code>pip install \"sqlstream[all]\"\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#cli-usage","title":"CLI Usage","text":"<pre><code># Simple query\n$ sqlstream query data.csv \"SELECT name, age FROM data WHERE age &gt; 25\"\n\n# With output format\n$ sqlstream query data.csv \"SELECT * FROM data\" --format json\n\n# Show execution time\n$ sqlstream query data.csv \"SELECT * FROM data\" --time\n\n# Use pandas backend for performance\n$ sqlstream query data.parquet \"SELECT * FROM data\" --backend pandas\n</code></pre>"},{"location":"#python-api","title":"Python API","text":"<pre><code>from sqlstream import query\n\n# Execute query\nresults = query(\"data.csv\").sql(\"SELECT * FROM data WHERE age &gt; 25\")\n\n# Iterate over results (lazy evaluation)\nfor row in results:\n    print(row)\n\n# Or convert to list\nresults_list = query(\"data.csv\").sql(\"SELECT * FROM data\").to_list()\n</code></pre>"},{"location":"#why-sqlstream","title":"Why SQLStream?","text":"<p>Perfect For</p> <ul> <li>Data Exploration: Quick analysis without database setup</li> <li>ETL Pipelines: Process CSV/Parquet files with SQL</li> <li>Data Science: Filter and join datasets before pandas</li> <li>DevOps: Query logs and data files in CI/CD</li> <li>Learning: Understand query execution internals</li> </ul> <p>Not For</p> <ul> <li>Large Databases: Use PostgreSQL, MySQL instead</li> <li>Real-time Analytics: Use ClickHouse, DuckDB</li> <li>Production OLTP: SQLStream is read-only</li> </ul>"},{"location":"#performance","title":"Performance","text":"<p>SQLStream offers two execution backends:</p> Backend Speed Use Case Python Baseline Learning, small files (&lt;100K rows) Pandas 10-100x faster Production, large files (&gt;100K rows) <p>Performance Tips</p> <ul> <li>Use <code>--backend pandas</code> for files &gt;100K rows</li> <li>Use column pruning: <code>SELECT name, age</code> instead of <code>SELECT *</code></li> <li>Add WHERE filters to reduce data scanned</li> <li>Use Parquet format for better compression</li> </ul>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li> <p> Quick Start Guide</p> <p>Get up and running in 5 minutes with hands-on examples.</p> </li> <li> <p> SQL Reference</p> <p>Learn about supported SQL syntax and features.</p> </li> <li> <p> CLI Reference</p> <p>Complete guide to the command-line interface.</p> </li> <li> <p> Python API</p> <p>Deep dive into the programmatic API.</p> </li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>SQLStream is in active development. Current phase: 7.6</p> <ul> <li>\u2705 Phase 0-2: Core query engine with Volcano model</li> <li>\u2705 Phase 3: Parquet support</li> <li>\u2705 Phase 4: Aggregations &amp; GROUP BY</li> <li>\u2705 Phase 5: JOIN operations (INNER, LEFT, RIGHT)</li> <li>\u2705 Phase 5.5: Pandas backend (10-100x speedup)</li> <li>\u2705 Phase 6: HTTP data sources</li> <li>\u2705 Phase 7: CLI with beautiful output</li> <li>\u2705 Phase 7.5: Interactive mode with Textual</li> <li>\u2705 Phase 7.6: Inline file path support</li> <li>\ud83d\udea7 Phase 8: Type system &amp; schema inference</li> <li>\ud83d\udea7 Phase 9: Error handling &amp; user feedback</li> </ul>"},{"location":"#license","title":"License","text":"<p>SQLStream is licensed under the MIT License.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! See the Contributing Guide for details.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions to SQLStream are welcome!</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/subhayu99/sqlstream.git\ncd sqlstream\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<pre><code>ruff check .\nruff format .\n</code></pre>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Add tests</li> <li>Submit a pull request</li> </ol>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Report bugs and request features at GitHub Issues.</p>"},{"location":"api/overview/","title":"Python API Overview","text":"<p>Use SQLStream programmatically in your Python code.</p>"},{"location":"api/overview/#basic-usage","title":"Basic Usage","text":"<pre><code>from sqlstream import query\n\n# Execute query\nresults = query(\"data.csv\").sql(\"SELECT * FROM data WHERE age &gt; 25\")\n\n# Iterate (lazy)\nfor row in results:\n    print(row)\n\n# Or convert to list (eager)\nresults_list = query(\"data.csv\").sql(\"SELECT * FROM data\").to_list()\n</code></pre>"},{"location":"api/overview/#api-reference","title":"API Reference","text":"<ul> <li>Query Class</li> <li>Readers</li> <li>Advanced Usage</li> </ul>"},{"location":"cli/overview/","title":"CLI Overview","text":"<p>The <code>sqlstream</code> command-line interface provides an easy way to query data files.</p>"},{"location":"cli/overview/#basic-usage","title":"Basic Usage","text":"<pre><code>sqlstream query [FILE] &lt;SQL&gt; [OPTIONS]\n</code></pre>"},{"location":"cli/overview/#quick-examples","title":"Quick Examples","text":"<pre><code># Query a file\nsqlstream query data.csv \"SELECT * FROM data\"\n\n# Inline file path\nsqlstream query \"SELECT * FROM 'data.csv'\"\n\n# JSON output\nsqlstream query data.csv \"SELECT * FROM data\" --format json\n\n# Interactive mode\nsqlstream query data.csv \"SELECT * FROM data\" --interactive\n</code></pre>"},{"location":"cli/overview/#available-commands","title":"Available Commands","text":"<ul> <li><code>query</code> - Execute SQL queries on data files</li> <li><code>interactive</code> - Launch interactive query interface (coming soon)</li> </ul>"},{"location":"cli/overview/#global-options","title":"Global Options","text":"<ul> <li><code>--version</code> - Show version</li> <li><code>--help</code> - Show help message</li> </ul>"},{"location":"cli/query-command/","title":"Query Command","text":"<p>Execute SQL queries on CSV and Parquet files.</p>"},{"location":"cli/query-command/#syntax","title":"Syntax","text":"<pre><code>sqlstream query [FILE_OR_SQL] [SQL] [OPTIONS]\n</code></pre>"},{"location":"cli/query-command/#arguments","title":"Arguments","text":"<ul> <li><code>FILE_OR_SQL</code> - File path or SQL query (optional if SQL contains inline paths)</li> <li><code>SQL</code> - SQL query string (optional if using inline paths)</li> </ul>"},{"location":"cli/query-command/#options","title":"Options","text":""},{"location":"cli/query-command/#output-format","title":"Output Format","text":"<ul> <li><code>-f, --format [table|json|csv]</code> - Output format (default: table)</li> <li><code>-o, --output FILE</code> - Write output to file</li> </ul>"},{"location":"cli/query-command/#performance","title":"Performance","text":"<ul> <li><code>-b, --backend [auto|pandas|python]</code> - Execution backend (default: auto)</li> <li><code>-l, --limit N</code> - Limit displayed rows</li> </ul>"},{"location":"cli/query-command/#display","title":"Display","text":"<ul> <li><code>--no-color</code> - Disable colored output</li> <li><code>-i, --interactive</code> - Force interactive mode</li> <li><code>--no-interactive</code> - Disable interactive mode</li> <li><code>-t, --time</code> - Show execution time</li> </ul>"},{"location":"cli/query-command/#debugging","title":"Debugging","text":"<ul> <li><code>--explain</code> - Show query execution plan</li> </ul>"},{"location":"cli/query-command/#examples","title":"Examples","text":"<p>See Query Examples</p>"},{"location":"examples/basic-queries/","title":"Basic Query Examples","text":"<p>Common query patterns and examples.</p>"},{"location":"examples/basic-queries/#filtering","title":"Filtering","text":"<pre><code>SELECT * FROM data WHERE age &gt; 25\nSELECT * FROM data WHERE city = 'NYC'\nSELECT * FROM data WHERE salary &gt;= 80000\n</code></pre>"},{"location":"examples/basic-queries/#sorting","title":"Sorting","text":"<pre><code>SELECT * FROM data ORDER BY age DESC\nSELECT * FROM data ORDER BY salary DESC LIMIT 10\n</code></pre>"},{"location":"examples/basic-queries/#aggregations","title":"Aggregations","text":"<pre><code>SELECT COUNT(*) FROM data\nSELECT AVG(salary) FROM data\nSELECT department, COUNT(*) FROM data GROUP BY department\n</code></pre> <p>See more: Join Examples | Aggregations</p>"},{"location":"features/data-sources/","title":"Data Sources","text":"<p>SQLStream supports multiple data source types.</p>"},{"location":"features/data-sources/#csv-files","title":"CSV Files","text":"<pre><code>from sqlstream import query\n\n# Local CSV\nresults = query(\"data.csv\").sql(\"SELECT * FROM data\")\n\n# CSV with custom delimiter\n# Auto-detected: comma, tab, pipe, semicolon\n</code></pre>"},{"location":"features/data-sources/#parquet-files","title":"Parquet Files","text":"<pre><code>pip install \"sqlstream[parquet]\"\n</code></pre> <pre><code>results = query(\"data.parquet\").sql(\"SELECT * FROM data\")\n</code></pre>"},{"location":"features/data-sources/#http-urls","title":"HTTP URLs","text":"<pre><code>pip install \"sqlstream[http]\"\n</code></pre> <pre><code>results = query(\"https://example.com/data.csv\").sql(\"SELECT * FROM data\")\n</code></pre>"},{"location":"features/data-sources/#inline-paths","title":"Inline Paths","text":"<pre><code>sqlstream query \"SELECT * FROM 'data.csv'\"\nsqlstream query \"SELECT * FROM 'data.parquet'\"\nsqlstream query \"SELECT * FROM 'https://example.com/data.csv'\"\n</code></pre>"},{"location":"features/sql-support/","title":"SQL Support","text":"<p>SQLStream supports a practical subset of SQL designed for data exploration and ETL tasks.</p>"},{"location":"features/sql-support/#supported-syntax","title":"Supported Syntax","text":""},{"location":"features/sql-support/#select","title":"SELECT","text":"<pre><code>-- Select all columns\nSELECT * FROM data\n\n-- Select specific columns\nSELECT name, age, city FROM data\n\n-- With table alias\nSELECT d.name, d.age FROM data d\n</code></pre>"},{"location":"features/sql-support/#where","title":"WHERE","text":"<pre><code>-- Simple conditions\nSELECT * FROM data WHERE age &gt; 25\nSELECT * FROM data WHERE name = 'Alice'\nSELECT * FROM data WHERE salary &gt;= 80000\n\n-- Multiple conditions with AND\nSELECT * FROM data WHERE age &gt; 25 AND city = 'NYC'\nSELECT * FROM data WHERE salary &gt; 80000 AND department = 'Engineering'\n</code></pre> <p>Supported operators: <code>=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>, <code>!=</code>, <code>&lt;&gt;</code></p>"},{"location":"features/sql-support/#group-by","title":"GROUP BY","text":"<pre><code>-- Simple grouping\nSELECT city, COUNT(*) FROM data GROUP BY city\n\n-- Multiple columns\nSELECT department, city, AVG(salary) FROM data GROUP BY department, city\n\n-- With WHERE\nSELECT city, COUNT(*) FROM data WHERE age &gt; 25 GROUP BY city\n</code></pre>"},{"location":"features/sql-support/#aggregate-functions","title":"Aggregate Functions","text":"<pre><code>SELECT COUNT(*) FROM data\nSELECT COUNT(id) FROM data\nSELECT SUM(salary) FROM data\nSELECT AVG(age) FROM data\nSELECT MIN(salary) FROM data\nSELECT MAX(salary) FROM data\n</code></pre> <p>With aliases: <pre><code>SELECT department, COUNT(*) AS employee_count, AVG(salary) AS avg_salary\nFROM data\nGROUP BY department\n</code></pre></p>"},{"location":"features/sql-support/#join","title":"JOIN","text":"<pre><code>-- INNER JOIN\nSELECT * FROM employees e\nINNER JOIN departments d ON e.dept_id = d.id\n\n-- LEFT JOIN\nSELECT * FROM employees e\nLEFT JOIN departments d ON e.dept_id = d.id\n\n-- RIGHT JOIN\nSELECT * FROM employees e\nRIGHT JOIN departments d ON e.dept_id = d.id\n</code></pre>"},{"location":"features/sql-support/#order-by","title":"ORDER BY","text":"<pre><code>-- Ascending (default)\nSELECT * FROM data ORDER BY age\nSELECT * FROM data ORDER BY age ASC\n\n-- Descending\nSELECT * FROM data ORDER BY salary DESC\n\n-- Multiple columns\nSELECT * FROM data ORDER BY city ASC, age DESC\n</code></pre>"},{"location":"features/sql-support/#limit","title":"LIMIT","text":"<pre><code>-- Top 10 rows\nSELECT * FROM data LIMIT 10\n\n-- With ORDER BY\nSELECT * FROM data ORDER BY salary DESC LIMIT 5\n</code></pre>"},{"location":"features/sql-support/#complete-example","title":"Complete Example","text":"<pre><code>SELECT\n    department,\n    COUNT(*) AS employee_count,\n    AVG(salary) AS avg_salary,\n    MIN(salary) AS min_salary,\n    MAX(salary) AS max_salary\nFROM employees\nWHERE hire_date &gt; '2020-01-01'\n  AND status = 'active'\nGROUP BY department\nHAVING COUNT(*) &gt; 5\nORDER BY avg_salary DESC\nLIMIT 10\n</code></pre>"},{"location":"features/sql-support/#inline-file-paths-phase-76","title":"Inline File Paths (Phase 7.6)","text":"<pre><code># Single file\nsqlstream query \"SELECT * FROM 'data.csv' WHERE age &gt; 25\"\n\n# Multiple files with JOIN\nsqlstream query \"SELECT c.name, o.total FROM 'customers.csv' c JOIN 'orders.csv' o ON c.id = o.customer_id\"\n\n# Quoted paths (for spaces)\nsqlstream query \"SELECT * FROM '/path/with spaces/data.csv'\"\n</code></pre>"},{"location":"features/sql-support/#not-yet-supported","title":"Not Yet Supported","text":"<p>The following SQL features are planned but not yet implemented:</p> <ul> <li>\u274c Subqueries</li> <li>\u274c UNION/INTERSECT/EXCEPT</li> <li>\u274c HAVING clause</li> <li>\u274c CASE expressions</li> <li>\u274c String functions (UPPER, LOWER, etc.)</li> <li>\u274c Date functions</li> <li>\u274c Window functions</li> <li>\u274c Common Table Expressions (WITH)</li> </ul>"},{"location":"features/sql-support/#next-steps","title":"Next Steps","text":"<ul> <li>JOIN Examples</li> <li>Aggregation Examples</li> <li>Inline File Paths</li> </ul>"},{"location":"features/type-system/","title":"Type System &amp; Schema Inference","text":"<p>SQLStream includes a robust type system that automatically infers data types from your files and validates operations.</p>"},{"location":"features/type-system/#supported-types","title":"Supported Types","text":"<p>SQLStream supports six core data types:</p> Type Python Types Example Values <code>INTEGER</code> <code>int</code> <code>42</code>, <code>-100</code>, <code>0</code> <code>FLOAT</code> <code>float</code> <code>3.14</code>, <code>-2.5</code>, <code>0.0</code> <code>STRING</code> <code>str</code> <code>\"hello\"</code>, <code>\"Alice\"</code> <code>BOOLEAN</code> <code>bool</code> <code>true</code>, <code>false</code> <code>DATE</code> <code>date</code>, <code>datetime</code> <code>2024-01-15</code> <code>NULL</code> <code>None</code> Empty values"},{"location":"features/type-system/#automatic-type-inference","title":"Automatic Type Inference","text":"<p>SQLStream automatically infers types from your data:</p>"},{"location":"features/type-system/#from-python-values","title":"From Python Values","text":"<pre><code>from sqlstream.core.types import infer_type, DataType\n\ninfer_type(42)           # DataType.INTEGER\ninfer_type(3.14)         # DataType.FLOAT\ninfer_type(\"hello\")      # DataType.STRING\ninfer_type(True)         # DataType.BOOLEAN\ninfer_type(None)         # DataType.NULL\n</code></pre>"},{"location":"features/type-system/#from-string-values","title":"From String Values","text":"<p>When reading CSV files, SQLStream tries to infer the most specific type:</p> <pre><code>infer_type(\"42\")         # DataType.INTEGER (not STRING)\ninfer_type(\"3.14\")       # DataType.FLOAT\ninfer_type(\"true\")       # DataType.BOOLEAN\ninfer_type(\"2024-01-15\") # DataType.DATE\ninfer_type(\"hello\")      # DataType.STRING\n</code></pre>"},{"location":"features/type-system/#handling-mixed-types","title":"Handling Mixed Types","text":"<p>When a column has mixed types, SQLStream promotes to the most general compatible type:</p> <pre><code>from sqlstream.core.types import infer_common_type\n\n# Mixed integers and floats -&gt; FLOAT\ninfer_common_type([1, 2.5, 3])           # DataType.FLOAT\n\n# Mixed types -&gt; STRING\ninfer_common_type([1, \"hello\", 3])       # DataType.STRING\n\n# NULL values are ignored\ninfer_common_type([1, None, 3])          # DataType.INTEGER\n</code></pre>"},{"location":"features/type-system/#schema-inference","title":"Schema Inference","text":"<p>SQLStream automatically infers the schema (column names and types) when reading files.</p>"},{"location":"features/type-system/#basic-usage","title":"Basic Usage","text":"<pre><code>from sqlstream import query\n\n# Create query object\nq = query(\"employees.csv\")\n\n# Get inferred schema\nschema = q.schema()\n\n# Check column types\nprint(schema[\"name\"])    # DataType.STRING\nprint(schema[\"age\"])     # DataType.INTEGER\nprint(schema[\"salary\"])  # DataType.FLOAT\n</code></pre>"},{"location":"features/type-system/#schema-object","title":"Schema Object","text":"<p>The <code>Schema</code> object provides helpful methods:</p> <pre><code># Get all column names\ncolumns = schema.get_column_names()\n# ['name', 'age', 'salary', 'hire_date']\n\n# Get type of a column\nage_type = schema.get_column_type(\"age\")\n# DataType.INTEGER\n\n# Check if column exists\nif \"email\" in schema:\n    print(\"Email column exists\")\n\n# Validate column\ntry:\n    schema.validate_column(\"invalid_column\")\nexcept ValueError as e:\n    print(e)  # Column 'invalid_column' not found\n</code></pre>"},{"location":"features/type-system/#sample-size","title":"Sample Size","text":"<p>By default, SQLStream samples 100 rows to infer types. You can adjust this:</p> <pre><code>from sqlstream.readers.csv_reader import CSVReader\n\nreader = CSVReader(\"large_file.csv\")\n\n# Sample only 10 rows (faster)\nschema = reader.get_schema(sample_size=10)\n\n# Sample 1000 rows (more accurate)\nschema = reader.get_schema(sample_size=1000)\n</code></pre>"},{"location":"features/type-system/#type-checking","title":"Type Checking","text":""},{"location":"features/type-system/#numeric-types","title":"Numeric Types","text":"<p>Check if a type is numeric:</p> <pre><code>DataType.INTEGER.is_numeric()  # True\nDataType.FLOAT.is_numeric()    # True\nDataType.STRING.is_numeric()   # False\n</code></pre>"},{"location":"features/type-system/#type-compatibility","title":"Type Compatibility","text":"<p>Check if two types can be compared:</p> <pre><code># Same types are compatible\nDataType.INTEGER.is_comparable(DataType.INTEGER)  # True\n\n# Numeric types are compatible\nDataType.INTEGER.is_comparable(DataType.FLOAT)    # True\n\n# String and number are not compatible\nDataType.STRING.is_comparable(DataType.INTEGER)   # False\n\n# NULL is compatible with everything\nDataType.NULL.is_comparable(DataType.STRING)      # True\n</code></pre>"},{"location":"features/type-system/#type-coercion","title":"Type Coercion","text":"<p>When mixing types, SQLStream promotes to the more general type:</p> <pre><code># INT + FLOAT -&gt; FLOAT\nDataType.INTEGER.coerce_to(DataType.FLOAT)  # DataType.FLOAT\n\n# NULL + anything -&gt; that type\nDataType.NULL.coerce_to(DataType.INTEGER)   # DataType.INTEGER\n\n# Incompatible types -&gt; STRING\nDataType.INTEGER.coerce_to(DataType.STRING) # DataType.STRING\n</code></pre>"},{"location":"features/type-system/#practical-examples","title":"Practical Examples","text":""},{"location":"features/type-system/#example-1-validate-query-columns","title":"Example 1: Validate Query Columns","text":"<pre><code>from sqlstream import query\n\nq = query(\"employees.csv\")\nschema = q.schema()\n\n# Validate SELECT columns before executing\nselect_cols = [\"name\", \"age\", \"salary\"]\nfor col in select_cols:\n    try:\n        schema.validate_column(col)\n    except ValueError:\n        print(f\"Column '{col}' doesn't exist!\")\n</code></pre>"},{"location":"features/type-system/#example-2-check-column-types","title":"Example 2: Check Column Types","text":"<pre><code>from sqlstream import query\n\nq = query(\"sales.csv\")\nschema = q.schema()\n\n# Find all numeric columns\nnumeric_cols = [\n    col for col in schema.get_column_names()\n    if schema[col].is_numeric()\n]\nprint(f\"Numeric columns: {numeric_cols}\")\n</code></pre>"},{"location":"features/type-system/#example-3-type-safe-filtering","title":"Example 3: Type-Safe Filtering","text":"<pre><code>from sqlstream import query\nfrom sqlstream.core.types import DataType\n\nq = query(\"products.csv\")\nschema = q.schema()\n\n# Only filter on numeric columns\nif schema[\"price\"].is_numeric():\n    results = q.sql(\"SELECT * FROM data WHERE price &gt; 100\")\nelse:\n    print(\"Price column is not numeric!\")\n</code></pre>"},{"location":"features/type-system/#schema-merging","title":"Schema Merging","text":"<p>When working with multiple files (e.g., in JOINs), SQLStream can merge schemas:</p> <pre><code>from sqlstream.core.types import Schema, DataType\n\n# Two schemas with overlapping columns\nschema1 = Schema({\n    \"id\": DataType.INTEGER,\n    \"value\": DataType.INTEGER\n})\n\nschema2 = Schema({\n    \"id\": DataType.INTEGER,\n    \"value\": DataType.FLOAT  # Different type!\n})\n\n# Merge schemas\nmerged = schema1.merge(schema2)\n\n# 'value' column is promoted to FLOAT\nprint(merged[\"value\"])  # DataType.FLOAT\n</code></pre>"},{"location":"features/type-system/#best-practices","title":"Best Practices","text":""},{"location":"features/type-system/#1-check-schema-before-querying","title":"1. Check Schema Before Querying","text":"<pre><code>schema = query(\"data.csv\").schema()\n\n# Verify expected columns exist\nrequired = [\"id\", \"name\", \"amount\"]\nfor col in required:\n    schema.validate_column(col)  # Raises error if missing\n</code></pre>"},{"location":"features/type-system/#2-use-type-information","title":"2. Use Type Information","text":"<pre><code>schema = query(\"data.csv\").schema()\n\n# Only perform numeric operations on numeric columns\nif schema[\"age\"].is_numeric():\n    results = query(\"data.csv\").sql(\"SELECT AVG(age) FROM data\")\n</code></pre>"},{"location":"features/type-system/#3-handle-null-values","title":"3. Handle NULL Values","text":"<pre><code>from sqlstream.core.types import DataType\n\nschema = query(\"data.csv\").schema()\n\n# Check if column might have nulls\nif schema[\"optional_field\"] == DataType.NULL:\n    print(\"This column is all nulls!\")\n</code></pre>"},{"location":"features/type-system/#4-sample-size-tradeoff","title":"4. Sample Size Tradeoff","text":"<pre><code>from sqlstream.readers.csv_reader import CSVReader\n\n# Small sample (fast, less accurate)\nschema = CSVReader(\"file.csv\").get_schema(sample_size=10)\n\n# Large sample (slower, more accurate)\nschema = CSVReader(\"file.csv\").get_schema(sample_size=1000)\n</code></pre>"},{"location":"features/type-system/#type-system-api-reference","title":"Type System API Reference","text":""},{"location":"features/type-system/#datatype-methods","title":"DataType Methods","text":"<ul> <li><code>is_numeric()</code> - Check if type is INTEGER or FLOAT</li> <li><code>is_comparable(other)</code> - Check if compatible for comparison</li> <li><code>coerce_to(other)</code> - Determine result type of coercion</li> </ul>"},{"location":"features/type-system/#schema-methods","title":"Schema Methods","text":"<ul> <li><code>get_column_names()</code> - Get list of column names</li> <li><code>get_column_type(column)</code> - Get type of column (or None)</li> <li><code>validate_column(column)</code> - Raise error if column doesn't exist</li> <li><code>merge(other)</code> - Merge two schemas with type coercion</li> <li><code>from_row(row)</code> - Create schema from single row</li> <li><code>from_rows(rows)</code> - Create schema from multiple rows (more accurate)</li> </ul>"},{"location":"features/type-system/#type-inference-functions","title":"Type Inference Functions","text":"<ul> <li><code>infer_type(value)</code> - Infer type from Python value</li> <li><code>infer_common_type(values)</code> - Infer common type from list of values</li> </ul>"},{"location":"features/type-system/#next-steps","title":"Next Steps","text":"<ul> <li>SQL Support - See what SQL features use the type system</li> <li>Data Sources - Learn about different file formats</li> <li>Python API - Use the type system programmatically</li> </ul>"},{"location":"getting-started/core-concepts/","title":"Core Concepts","text":"<p>Understanding the key concepts behind SQLStream will help you use it more effectively.</p>"},{"location":"getting-started/core-concepts/#architecture-overview","title":"Architecture Overview","text":"<p>SQLStream is built around these core components:</p> <pre><code>graph LR\n    A[SQL Query] --&gt; B[Parser]\n    B --&gt; C[AST]\n    C --&gt; D[Planner]\n    D --&gt; E[Optimized Plan]\n    E --&gt; F[Executor]\n    F --&gt; G[Operators]\n    G --&gt; H[Readers]\n    H --&gt; I[Data Sources]\n</code></pre>"},{"location":"getting-started/core-concepts/#the-volcano-model","title":"The Volcano Model","text":"<p>SQLStream uses the Volcano iterator model for query execution:</p>"},{"location":"getting-started/core-concepts/#what-is-it","title":"What is it?","text":"<p>Each operator in the query plan implements two methods:</p> <ul> <li><code>open()</code>: Initialize the operator</li> <li><code>next()</code>: Return the next row (or None when done)</li> </ul>"},{"location":"getting-started/core-concepts/#why-volcano","title":"Why Volcano?","text":"<p>\u2705 Lazy Evaluation: Rows are produced on-demand \u2705 Low Memory: Only one row in memory at a time \u2705 Composable: Operators stack like LEGO blocks \u2705 Predictable: Easy to understand and debug</p>"},{"location":"getting-started/core-concepts/#example","title":"Example","text":"<pre><code>SELECT name FROM employees WHERE salary &gt; 80000 LIMIT 5\n</code></pre> <p>Execution flow:</p> <pre><code>Limit(5)\n  \u2193 next()\nProject(name)\n  \u2193 next()\nFilter(salary &gt; 80000)\n  \u2193 next()\nScan(employees.csv)\n  \u2193 next()\nCSV Reader\n</code></pre> <p>Each operator calls <code>next()</code> on the operator below it until it gets a row.</p>"},{"location":"getting-started/core-concepts/#execution-backends","title":"Execution Backends","text":"<p>SQLStream offers two execution backends:</p>"},{"location":"getting-started/core-concepts/#python-backend","title":"Python Backend","text":"<p>How it works: Pure Python implementation using the Volcano model</p> <p>Pros:</p> <ul> <li>\u2705 No dependencies</li> <li>\u2705 Easy to understand</li> <li>\u2705 Works everywhere</li> </ul> <p>Cons:</p> <ul> <li>\u274c Slower for large datasets</li> <li>\u274c Row-at-a-time processing</li> </ul> <p>Best for:</p> <ul> <li>Learning and education</li> <li>Small files (&lt;100K rows)</li> <li>Quick prototyping</li> </ul>"},{"location":"getting-started/core-concepts/#pandas-backend","title":"Pandas Backend","text":"<p>How it works: Translates SQL to pandas operations</p> <p>Pros:</p> <ul> <li>\u2705 10-100x faster than Python backend</li> <li>\u2705 Vectorized operations</li> <li>\u2705 Optimized C code</li> </ul> <p>Cons:</p> <ul> <li>\u274c Requires pandas dependency</li> <li>\u274c Loads full dataset into memory</li> </ul> <p>Best for:</p> <ul> <li>Production workloads</li> <li>Large files (&gt;100K rows)</li> <li>Performance-critical applications</li> </ul>"},{"location":"getting-started/core-concepts/#query-optimizations","title":"Query Optimizations","text":"<p>SQLStream applies several optimizations automatically:</p>"},{"location":"getting-started/core-concepts/#1-column-pruning","title":"1. Column Pruning","text":"<p>What: Only read columns that are actually used</p> <p>Example:</p> <pre><code>SELECT name FROM employees\n</code></pre> <p>SQLStream only reads the <code>name</code> column from the CSV, not all columns.</p> <p>Benefit: Faster I/O, less memory</p>"},{"location":"getting-started/core-concepts/#2-predicate-pushdown","title":"2. Predicate Pushdown","text":"<p>What: Apply filters as early as possible</p> <p>Example:</p> <pre><code>SELECT name FROM employees WHERE department = 'Engineering'\n</code></pre> <p>The filter is applied during the scan, not after loading all rows.</p> <p>Benefit: Fewer rows to process</p>"},{"location":"getting-started/core-concepts/#3-lazy-evaluation","title":"3. Lazy Evaluation","text":"<p>What: Only compute results when needed</p> <p>Example:</p> <pre><code>results = query(\"data.csv\").sql(\"SELECT * FROM data LIMIT 10\")\n# Nothing executed yet!\n\nfor row in results:\n    print(row)  # Now it executes, one row at a time\n</code></pre> <p>Benefit: Save computation for unused results</p>"},{"location":"getting-started/core-concepts/#data-sources","title":"Data Sources","text":"<p>SQLStream supports multiple data sources:</p>"},{"location":"getting-started/core-concepts/#csv-files","title":"CSV Files","text":"<pre><code>query(\"data.csv\")\n</code></pre> <ul> <li>Automatic delimiter detection</li> <li>Header row inference</li> <li>Type inference (strings, numbers)</li> </ul>"},{"location":"getting-started/core-concepts/#parquet-files","title":"Parquet Files","text":"<pre><code>query(\"data.parquet\")  # Requires: pip install \"sqlstream[parquet]\"\n</code></pre> <ul> <li>Columnar storage</li> <li>Better compression</li> <li>Schema included</li> </ul>"},{"location":"getting-started/core-concepts/#http-urls","title":"HTTP URLs","text":"<pre><code>query(\"https://example.com/data.csv\")  # Requires: pip install \"sqlstream[http]\"\n</code></pre> <ul> <li>Streaming support</li> <li>Automatic format detection</li> <li>Caching (planned)</li> </ul>"},{"location":"getting-started/core-concepts/#inline-paths-phase-76","title":"Inline Paths (Phase 7.6)","text":"<pre><code>sqlstream query \"SELECT * FROM 'data.csv'\"\n</code></pre> <ul> <li>No need to pre-specify file</li> <li>Multi-file queries</li> <li>More intuitive</li> </ul>"},{"location":"getting-started/core-concepts/#lazy-vs-eager-evaluation","title":"Lazy vs. Eager Evaluation","text":""},{"location":"getting-started/core-concepts/#lazy-default","title":"Lazy (Default)","text":"<pre><code>result = query(\"data.csv\").sql(\"SELECT * FROM data\")\n# \u2705 Nothing executed yet\n\nfor row in result:  # Executes one row at a time\n    print(row)\n</code></pre> <p>Advantages:</p> <ul> <li>Low memory usage</li> <li>Can process infinite streams</li> <li>Early termination possible</li> </ul>"},{"location":"getting-started/core-concepts/#eager","title":"Eager","text":"<pre><code>result = query(\"data.csv\").sql(\"SELECT * FROM data\").to_list()\n# \u274c Executes immediately, loads all data\n</code></pre> <p>Advantages:</p> <ul> <li>Random access to results</li> <li>Easier to work with</li> <li>Can get length with <code>len()</code></li> </ul> <p>Choose lazy when:</p> <ul> <li>Processing large files</li> <li>Only need first N results</li> <li>Streaming to another system</li> </ul> <p>Choose eager when:</p> <ul> <li>Results fit in memory</li> <li>Need to access results multiple times</li> <li>Using with pandas/numpy</li> </ul>"},{"location":"getting-started/core-concepts/#query-lifecycle","title":"Query Lifecycle","text":"<ol> <li>Parse: SQL string \u2192 AST (Abstract Syntax Tree)</li> <li>Plan: AST \u2192 Execution plan</li> <li>Optimize: Apply optimizations (column pruning, etc.)</li> <li>Execute: Build operator pipeline</li> <li>Iterate: Pull rows through the pipeline</li> </ol>"},{"location":"getting-started/core-concepts/#memory-model","title":"Memory Model","text":""},{"location":"getting-started/core-concepts/#python-backend_1","title":"Python Backend","text":"<pre><code>Memory Usage = O(1)  # One row at a time\n</code></pre> <p>Perfect for:</p> <ul> <li>Large files that don't fit in RAM</li> <li>Streaming applications</li> <li>Long-running processes</li> </ul>"},{"location":"getting-started/core-concepts/#pandas-backend_1","title":"Pandas Backend","text":"<pre><code>Memory Usage = O(n)  # Full dataset in memory\n</code></pre> <p>Perfect for:</p> <ul> <li>Files that fit in RAM</li> <li>Multiple passes over data</li> <li>Complex aggregations</li> </ul>"},{"location":"getting-started/core-concepts/#error-handling","title":"Error Handling","text":"<p>SQLStream provides helpful error messages:</p>"},{"location":"getting-started/core-concepts/#parse-errors","title":"Parse Errors","text":"<pre><code>SELECT * FORM data  # Typo: FORM instead of FROM\n</code></pre> <pre><code>Error: Expected 'FROM' but got 'FORM' at position 9\n</code></pre>"},{"location":"getting-started/core-concepts/#file-not-found","title":"File Not Found","text":"<pre><code>query(\"missing.csv\")\n</code></pre> <pre><code>Error: File not found - missing.csv\n</code></pre>"},{"location":"getting-started/core-concepts/#type-errors","title":"Type Errors","text":"<pre><code>SELECT * FROM data WHERE age &gt; 'thirty'  # Comparing number to string\n</code></pre> <pre><code>Error: Cannot compare age (int) with 'thirty' (str)\n</code></pre>"},{"location":"getting-started/core-concepts/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/core-concepts/#1-use-column-names","title":"1. Use Column Names","text":"<p>\u2705 Good: <pre><code>SELECT name, age FROM employees\n</code></pre></p> <p>\u274c Bad: <pre><code>SELECT * FROM employees\n</code></pre></p>"},{"location":"getting-started/core-concepts/#2-add-where-clauses","title":"2. Add WHERE Clauses","text":"<p>\u2705 Good: <pre><code>SELECT * FROM logs WHERE date = '2024-01-01'\n</code></pre></p> <p>\u274c Bad: <pre><code>SELECT * FROM logs  # Processes all rows\n</code></pre></p>"},{"location":"getting-started/core-concepts/#3-choose-the-right-backend","title":"3. Choose the Right Backend","text":"<pre><code># Small files (&lt;100K rows)\nquery(\"data.csv\").sql(\"SELECT * FROM data\", backend=\"python\")\n\n# Large files (&gt;100K rows)\nquery(\"data.csv\").sql(\"SELECT * FROM data\", backend=\"pandas\")\n</code></pre>"},{"location":"getting-started/core-concepts/#4-limit-results-early","title":"4. Limit Results Early","text":"<p>\u2705 Good: <pre><code>SELECT * FROM data WHERE active = true LIMIT 100\n</code></pre></p> <p>\u274c Bad: <pre><code>results = query(\"data.csv\").sql(\"SELECT * FROM data\").to_list()[:100]\n</code></pre></p>"},{"location":"getting-started/core-concepts/#5-use-lazy-evaluation","title":"5. Use Lazy Evaluation","text":"<p>\u2705 Good: <pre><code>for row in query(\"large.csv\").sql(\"SELECT * FROM large\"):\n    process(row)  # One row at a time\n</code></pre></p> <p>\u274c Bad: <pre><code>rows = query(\"large.csv\").sql(\"SELECT * FROM large\").to_list()\nfor row in rows:  # All rows in memory!\n    process(row)\n</code></pre></p>"},{"location":"getting-started/core-concepts/#next-steps","title":"Next Steps","text":"<ul> <li>SQL Support - Learn supported SQL syntax</li> <li>Pandas Backend - Deep dive into performance</li> <li>Architecture - Understand the internals</li> <li>Optimizations - How optimizations work</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>SQLStream offers multiple installation options depending on your needs.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python: 3.8 or higher</li> <li>OS: Linux, macOS, Windows</li> </ul>"},{"location":"getting-started/installation/#installation-options","title":"Installation Options","text":""},{"location":"getting-started/installation/#basic-installation-csv-only","title":"Basic Installation (CSV only)","text":"<p>For querying CSV files only:</p> <pre><code>pip install sqlstream\n</code></pre> <p>This gives you:</p> <ul> <li>\u2705 Core SQL engine</li> <li>\u2705 CSV file support</li> <li>\u2705 Basic CLI commands</li> <li>\u274c No Parquet support</li> <li>\u274c No performance optimizations</li> </ul>"},{"location":"getting-started/installation/#with-parquet-support","title":"With Parquet Support","text":"<p>To query both CSV and Parquet files:</p> <pre><code>pip install \"sqlstream[parquet]\"\n</code></pre> <p>Additional features:</p> <ul> <li>\u2705 Everything from basic install</li> <li>\u2705 Parquet file support via PyArrow</li> <li>\u2705 Better compression and performance</li> </ul>"},{"location":"getting-started/installation/#with-pandas-backend-recommended","title":"With Pandas Backend (Recommended)","text":"<p>For 10-100x performance boost with large files:</p> <pre><code>pip install \"sqlstream[pandas]\"\n</code></pre> <p>Additional features:</p> <ul> <li>\u2705 Everything from basic install</li> <li>\u2705 Parquet support</li> <li>\u2705 Pandas-powered execution (10-100x faster)</li> <li>\u2705 Optimized for large datasets (&gt;100K rows)</li> </ul>"},{"location":"getting-started/installation/#with-http-support","title":"With HTTP Support","text":"<p>To query CSV/Parquet files from URLs:</p> <pre><code>pip install \"sqlstream[http]\"\n</code></pre> <p>Additional features:</p> <ul> <li>\u2705 Query files from HTTP/HTTPS URLs</li> <li>\u2705 Automatic format detection</li> <li>\u2705 Streaming support for large remote files</li> </ul>"},{"location":"getting-started/installation/#with-cli-features","title":"With CLI Features","text":"<p>For beautiful terminal output and interactive mode:</p> <pre><code>pip install \"sqlstream[cli]\"\n</code></pre> <p>Additional features:</p> <ul> <li>\u2705 Rich table formatting</li> <li>\u2705 Interactive scrollable table viewer</li> <li>\u2705 Syntax highlighting</li> <li>\u2705 Multiple output formats (JSON, CSV, table)</li> </ul>"},{"location":"getting-started/installation/#all-features","title":"All Features","text":"<p>To install everything:</p> <pre><code>pip install \"sqlstream[all]\"\n</code></pre> <p>This includes:</p> <ul> <li>\u2705 CSV and Parquet support</li> <li>\u2705 Pandas backend</li> <li>\u2705 HTTP data sources</li> <li>\u2705 Full CLI with interactive mode</li> <li>\u2705 All output formats</li> </ul>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For contributing or development:</p> <pre><code># Clone the repository\ngit clone https://github.com/subhayu99/sqlstream.git\ncd sqlstream\n\n# Install in development mode with all dev dependencies\npip install -e \".[dev]\"\n</code></pre> <p>This includes:</p> <ul> <li>Testing: pytest, pytest-cov</li> <li>Linting: ruff</li> <li>Type checking: mypy</li> <li>Documentation: mkdocs, mkdocs-material</li> </ul>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify SQLStream is working:</p> <pre><code># Check version\nsqlstream --version\n\n# Run a quick query (requires a CSV file)\necho \"name,age\\nAlice,30\\nBob,25\" &gt; test.csv\nsqlstream query test.csv \"SELECT * FROM test\"\n</code></pre> <p>Expected output:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name  \u2502 age \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Alice \u2502  30 \u2502\n\u2502 Bob   \u2502  25 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n\n2 rows\n</code></pre>"},{"location":"getting-started/installation/#upgrading","title":"Upgrading","text":"<p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade sqlstream\n</code></pre> <p>To upgrade with all features:</p> <pre><code>pip install --upgrade \"sqlstream[all]\"\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<p>To remove SQLStream:</p> <pre><code>pip uninstall sqlstream\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If you see <code>ModuleNotFoundError</code>:</p> <pre><code># Reinstall with verbose output\npip install --verbose \"sqlstream[all]\"\n</code></pre>"},{"location":"getting-started/installation/#pandas-not-found","title":"Pandas Not Found","text":"<p>If you get \"pandas backend requested but pandas is not installed\":</p> <pre><code>pip install \"sqlstream[pandas]\"\n</code></pre>"},{"location":"getting-started/installation/#cli-not-working","title":"CLI Not Working","text":"<p>If <code>sqlstream</code> command is not found:</p> <pre><code># Check if it's in your PATH\nwhich sqlstream\n\n# Try running as module\npython -m sqlstream.cli.main --help\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Get started in 5 minutes</li> <li>Core Concepts - Understand the basics</li> <li>SQL Support - Learn supported SQL syntax</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with SQLStream in 5 minutes!</p>"},{"location":"getting-started/quickstart/#step-1-install-sqlstream","title":"Step 1: Install SQLStream","text":"<pre><code>pip install \"sqlstream[all]\"\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-create-sample-data","title":"Step 2: Create Sample Data","text":"<p>Create a sample CSV file:</p> <pre><code>cat &gt; employees.csv &lt;&lt; EOF\nid,name,department,salary,hire_date\n1,Alice,Engineering,95000,2020-01-15\n2,Bob,Sales,75000,2019-06-01\n3,Charlie,Engineering,105000,2018-03-20\n4,Diana,Marketing,68000,2021-02-14\n5,Eve,Sales,82000,2020-09-10\nEOF\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-your-first-query","title":"Step 3: Your First Query","text":""},{"location":"getting-started/quickstart/#cli-usage","title":"CLI Usage","text":"<pre><code># Select all rows\n$ sqlstream query employees.csv \"SELECT * FROM employees\"\n\n# Filter by department\n$ sqlstream query employees.csv \"SELECT name, salary FROM employees WHERE department = 'Engineering'\"\n\n# Sort by salary\n$ sqlstream query employees.csv \"SELECT * FROM employees ORDER BY salary DESC LIMIT 3\"\n</code></pre>"},{"location":"getting-started/quickstart/#python-api","title":"Python API","text":"<pre><code>from sqlstream import query\n\n# Simple query\nresults = query(\"employees.csv\").sql(\"SELECT * FROM employees WHERE salary &gt; 80000\")\n\n# Print results\nfor row in results:\n    print(f\"{row['name']}: ${row['salary']:,}\")\n</code></pre> <p>Output: <pre><code>Alice: $95,000\nCharlie: $105,000\nEve: $82,000\n</code></pre></p>"},{"location":"getting-started/quickstart/#step-4-advanced-features","title":"Step 4: Advanced Features","text":""},{"location":"getting-started/quickstart/#aggregations","title":"Aggregations","text":"<pre><code># Count employees by department\n$ sqlstream query employees.csv \"SELECT department, COUNT(*) AS count FROM employees GROUP BY department\"\n</code></pre> <p>Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 department  \u2502 count \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Engineering \u2502     2 \u2502\n\u2502 Sales       \u2502     2 \u2502\n\u2502 Marketing   \u2502     1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"getting-started/quickstart/#joins","title":"Joins","text":"<p>Create another file for orders:</p> <pre><code>cat &gt; orders.csv &lt;&lt; EOF\norder_id,employee_id,amount\n101,1,1500\n102,2,2300\n103,1,1800\n104,3,2100\nEOF\n</code></pre> <p>Join the two files:</p> <pre><code>$ sqlstream query \"SELECT e.name, o.amount FROM 'employees.csv' e JOIN 'orders.csv' o ON e.id = o.employee_id\"\n</code></pre> <p>Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 name    \u2502 amount \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Alice   \u2502   1500 \u2502\n\u2502 Bob     \u2502   2300 \u2502\n\u2502 Alice   \u2502   1800 \u2502\n\u2502 Charlie \u2502   2100 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"getting-started/quickstart/#output-formats","title":"Output Formats","text":"Table (default)JSONCSV <pre><code>$ sqlstream query employees.csv \"SELECT * FROM employees LIMIT 2\"\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 id \u2502 name  \u2502 department  \u2502 salary \u2502 hire_date  \u2502\n\u251c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  1 \u2502 Alice \u2502 Engineering \u2502  95000 \u2502 2020-01-15 \u2502\n\u2502  2 \u2502 Bob   \u2502 Sales       \u2502  75000 \u2502 2019-06-01 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>$ sqlstream query employees.csv \"SELECT * FROM employees LIMIT 2\" --format json\n</code></pre> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"Alice\",\n    \"department\": \"Engineering\",\n    \"salary\": 95000,\n    \"hire_date\": \"2020-01-15\"\n  },\n  {\n    \"id\": 2,\n    \"name\": \"Bob\",\n    \"department\": \"Sales\",\n    \"salary\": 75000,\n    \"hire_date\": \"2019-06-01\"\n  }\n]\n</code></pre> <pre><code>$ sqlstream query employees.csv \"SELECT * FROM employees LIMIT 2\" --format csv\n</code></pre> <pre><code>id,name,department,salary,hire_date\n1,Alice,Engineering,95000,2020-01-15\n2,Bob,Sales,75000,2019-06-01\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-performance-boost","title":"Step 5: Performance Boost","text":"<p>For large files, use the pandas backend:</p> <pre><code>$ sqlstream query large_file.csv \"SELECT * FROM large_file WHERE amount &gt; 1000\" --backend pandas\n</code></pre> <p>Performance comparison:</p> Rows Python Backend Pandas Backend Speedup 10K 0.5s 0.05s 10x 100K 5.2s 0.15s 35x 1M 52s 0.8s 65x"},{"location":"getting-started/quickstart/#step-6-interactive-mode","title":"Step 6: Interactive Mode","text":"<p>For wide tables, use interactive mode:</p> <pre><code>$ sqlstream query employees.csv \"SELECT * FROM employees\" --interactive\n</code></pre> <p>This launches a scrollable table viewer with:</p> <ul> <li>\u2b05\ufe0f\u27a1\ufe0f Horizontal scrolling (or <code>h</code>/<code>l</code>)</li> <li>\u2b06\ufe0f\u2b07\ufe0f Vertical scrolling (or <code>k</code>/<code>j</code>)</li> <li><code>q</code> or <code>Esc</code> to quit</li> </ul>"},{"location":"getting-started/quickstart/#common-workflows","title":"Common Workflows","text":""},{"location":"getting-started/quickstart/#data-exploration","title":"Data Exploration","text":"<pre><code># Check file structure\n$ head -5 data.csv\n\n# Count rows\n$ sqlstream query data.csv \"SELECT COUNT(*) FROM data\"\n\n# Show unique values\n$ sqlstream query data.csv \"SELECT DISTINCT category FROM data\"\n\n# Summary statistics\n$ sqlstream query data.csv \"SELECT MIN(price), MAX(price), AVG(price) FROM data\"\n</code></pre>"},{"location":"getting-started/quickstart/#data-cleaning","title":"Data Cleaning","text":"<pre><code>from sqlstream import query\n\n# Remove duplicates and filter nulls\nresults = query(\"messy_data.csv\").sql(\"\"\"\n    SELECT DISTINCT *\n    FROM messy_data\n    WHERE name IS NOT NULL\n      AND age &gt; 0\n    ORDER BY id\n\"\"\")\n\n# Export cleaned data\nimport csv\nwith open(\"clean_data.csv\", \"w\") as f:\n    writer = csv.DictWriter(f, fieldnames=results.to_list()[0].keys())\n    writer.writeheader()\n    writer.writerows(results.to_list())\n</code></pre>"},{"location":"getting-started/quickstart/#etl-pipeline","title":"ETL Pipeline","text":"<pre><code>from sqlstream import query\n\n# Extract\ncustomers = query(\"customers.csv\")\norders = query(\"orders.csv\")\n\n# Transform: Calculate total orders per customer\nresult = query(\"customers.csv\").sql(\"\"\"\n    SELECT c.name, COUNT(o.order_id) as total_orders\n    FROM customers c\n    JOIN orders o ON c.id = o.customer_id\n    GROUP BY c.name\n    HAVING COUNT(o.order_id) &gt; 5\n    ORDER BY total_orders DESC\n\"\"\")\n\n# Load\nfor row in result:\n    # Send to database, API, etc.\n    print(row)\n</code></pre>"},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"<p>Now that you're familiar with the basics, explore:</p> <ul> <li>Core Concepts - Understand how SQLStream works</li> <li>SQL Support - Learn all supported SQL features</li> <li>CLI Reference - Master the command-line interface</li> <li>Python API - Deep dive into the programmatic API</li> <li>Examples - More real-world examples</li> </ul>"},{"location":"getting-started/quickstart/#need-help","title":"Need Help?","text":"<ul> <li>\ud83d\udcd6 Documentation</li> <li>\ud83d\udc1b Report Issues</li> <li>\ud83d\udcac Discussions</li> </ul>"}]}